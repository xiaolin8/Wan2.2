#!/usr/bin/env python3
"""
Wan2.2-T2V-A14B-Diffusers - Kubernetes/Ray ç¯å¢ƒä¸“ç”¨è„šæœ¬
é’ˆå¯¹ RayJob å’Œ Kubernetes é›†ç¾¤ä¼˜åŒ–çš„åˆ†å¸ƒå¼è§†é¢‘ç”Ÿæˆè„šæœ¬
"""

import torch
import numpy as np
from diffusers import WanPipeline, AutoencoderKLWan
from diffusers.utils import export_to_video
import argparse
import os
import sys
import socket
import time

def setup_distributed():
    """è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒ"""
    print("=== åˆ†å¸ƒå¼ç¯å¢ƒè®¾ç½® ===")
    
    # æ£€æŸ¥ PyTorch å®‰è£…
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"GPU æ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
        print(f"è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
    
    # è®¾ç½®ç½‘ç»œç¯å¢ƒå˜é‡
    try:
        # è·å–æœ¬æœº IP
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        print(f"ä¸»æœºå: {hostname}")
        print(f"æœ¬åœ° IP: {local_ip}")
        
        # è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡
        os.environ['MASTER_ADDR'] = os.environ.get('MASTER_ADDR', local_ip)
        os.environ['MASTER_PORT'] = os.environ.get('MASTER_PORT', '29500')
        
        print(f"MASTER_ADDR: {os.environ.get('MASTER_ADDR')}")
        print(f"MASTER_PORT: {os.environ.get('MASTER_PORT')}")
        
    except Exception as e:
        print(f"ç½‘ç»œè®¾ç½®è­¦å‘Š: {e}")
        # ä½¿ç”¨é»˜è®¤å€¼
        os.environ['MASTER_ADDR'] = os.environ.get('MASTER_ADDR', '127.0.0.1')
        os.environ['MASTER_PORT'] = os.environ.get('MASTER_PORT', '29500')

def parse_args():
    parser = argparse.ArgumentParser(description="Run Wan2.2-T2V-A14B-Diffusers on Kubernetes/Ray")
    
    # --- Path Parameters ---
    parser.add_argument("--model_path", type=str, required=True, help="Path to the Diffusers model directory.")
    parser.add_argument("--output_path", type=str, required=True, help="Path to save the output video file.")
    
    # --- Generation Content Parameters ---
    parser.add_argument("--prompt", type=str, default="A robot surfing on a wave, cinematic", help="The text prompt.")
    parser.add_argument("--negative_prompt", type=str, default="è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°", help="The negative text prompt.")
    
    # --- Inference Detail Parameters ---
    parser.add_argument("--num_frames", type=int, default=16, help="Number of frames to generate.")
    parser.add_argument("--height", type=int, default=720, help="Video height.")
    parser.add_argument("--width", type=int, default=1280, help="Video width.")
    parser.add_argument("--num_inference_steps", type=int, default=20, help="Number of denoising steps.")
    parser.add_argument("--guidance_scale", type=float, default=4.0, help="Guidance scale (CFG).")
    parser.add_argument("--guidance_scale_2", type=float, default=3.0, help="Secondary guidance scale for WanPipeline.")
    parser.add_argument("--seed", type=int, default=1024, help="Random seed for reproducibility.")
    parser.add_argument("--fps", type=int, default=16, help="FPS for the output video.")

    # --- Model Loading Parameters ---
    parser.add_argument("--dtype", type=str, default="float16", choices=['bfloat16', 'float16', 'float32'], help="Data type for the main model.")
    parser.add_argument("--vae_subfolder", type=str, default="vae", help="Subfolder for the VAE model.")
    parser.add_argument("--vae_dtype", type=str, default="float16", choices=['float16', 'float32'], help="Data type for the VAE.")
    parser.add_argument('--disable_local_files_only', dest='local_files_only', action='store_false', help="Disable loading models from local files only. It is enabled by default.")
    parser.set_defaults(local_files_only=True)
    
    # --- Performance Parameters ---
    parser.add_argument("--enable_xformers", action="store_true", help="Enable xformers memory efficient attention.")
    parser.add_argument("--enable_cpu_offload", action="store_true", help="Enable CPU offload for memory optimization.")

    return parser.parse_args()

def load_model_safely(args):
    """å®‰å…¨åœ°åŠ è½½æ¨¡å‹"""
    print("=== æ¨¡å‹åŠ è½½ ===")
    
    # è®¾å¤‡è®¾ç½®
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype_map = {"bfloat16": torch.bfloat16, "float16": torch.float16, "float32": torch.float32}
    vae_dtype_map = {"float16": torch.float16, "float32": torch.float32}
    
    main_dtype = dtype_map.get(args.dtype)
    vae_dtype = vae_dtype_map.get(args.vae_dtype)
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"ä¸»æ¨¡å‹æ•°æ®ç±»å‹: {args.dtype}")
    print(f"VAE æ•°æ®ç±»å‹: {args.vae_dtype}")
    
    # åŠ è½½ VAE
    print("åŠ è½½ VAE...")
    try:
        vae = AutoencoderKLWan.from_pretrained(
            args.model_path, 
            subfolder=args.vae_subfolder, 
            torch_dtype=vae_dtype,
            local_files_only=args.local_files_only
        )
        print("VAE åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"VAE åŠ è½½å¤±è´¥: {e}")
        raise
    
    # åŠ è½½ä¸»æ¨¡å‹
    print("åŠ è½½ä¸»æ¨¡å‹...")
    try:
        pipe = WanPipeline.from_pretrained(
            args.model_path, 
            vae=vae, 
            torch_dtype=main_dtype,
            local_files_only=args.local_files_only
        )
        print("ä¸»æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"ä¸»æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise
    
    # ç§»åŠ¨åˆ°è®¾å¤‡
    if args.enable_cpu_offload:
        print("å¯ç”¨ CPU å¸è½½ä¼˜åŒ–...")
        try:
            pipe.enable_model_cpu_offload()
            print("CPU å¸è½½å¯ç”¨æˆåŠŸ")
        except Exception as e:
            print(f"CPU å¸è½½å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨ GPU: {e}")
            pipe.to(device)
    else:
        pipe.to(device)
    
    # å¯ç”¨ xFormers
    if args.enable_xformers:
        try:
            pipe.enable_xformers_memory_efficient_attention()
            print("xFormers å¯ç”¨æˆåŠŸ")
        except Exception as e:
            print(f"xFormers å¯ç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ³¨æ„åŠ›æœºåˆ¶")
    
    print("=== æ¨¡å‹åŠ è½½å®Œæˆ ===")
    return pipe

def main():
    """ä¸»å‡½æ•°"""
    print("Wan2.2-T2V-A14B-Diffusers Kubernetes/Ray ç¯å¢ƒå¯åŠ¨")
    print("=" * 60)
    
    # è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒ
    setup_distributed()
    
    # è§£æå‚æ•°
    args = parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(args.output_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•åˆ›å»º: {output_dir}")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # åŠ è½½æ¨¡å‹
        pipe = load_model_safely(args)
        
        # å‡†å¤‡ç”Ÿæˆå‚æ•°
        generator = torch.Generator(device=pipe.device if hasattr(pipe, 'device') else "cuda").manual_seed(args.seed)
        
        pipeline_kwargs = {
            "prompt": args.prompt,
            "negative_prompt": args.negative_prompt,
            "height": args.height,
            "width": args.width,
            "num_frames": args.num_frames,
            "num_inference_steps": args.num_inference_steps,
            "guidance_scale": args.guidance_scale,
            "guidance_scale_2": args.guidance_scale_2,
            "generator": generator,
        }
        
        print("\n=== ç”Ÿæˆå‚æ•° ===")
        for key, value in pipeline_kwargs.items():
            if key != 'generator':
                print(f"  {key}: {value}")
        print(f"  seed: {args.seed}")
        
        # ç”Ÿæˆè§†é¢‘
        print("\nå¼€å§‹ç”Ÿæˆè§†é¢‘...")
        output_frames = pipe(**pipeline_kwargs).frames[0]
        
        # ä¿å­˜è§†é¢‘
        print(f"ä¿å­˜è§†é¢‘åˆ°: {args.output_path}")
        export_to_video(output_frames, args.output_path, fps=args.fps)
        
        # è®¡ç®—è€—æ—¶
        end_time = time.time()
        duration = end_time - start_time
        
        print("\n" + "=" * 60)
        print("ğŸ‰ è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
        print(f"è¾“å‡ºæ–‡ä»¶: {args.output_path}")
        print(f"è€—æ—¶: {duration:.2f} ç§’")
        print(f"å®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)