## 第五章：关于视频时长的配置与说明

默认情况下，`wan2.2` 模型生成约 5 秒时长的视频。本章将说明如何通过环境变量灵活配置视频时长。

### 5.1 时长配置的原理

视频时长由两个核心参数决定：**帧率 (FPS)** 和 **总帧数 (Frame Number)**。

- **帧率 (`sample_fps`)**: 定义了视频每秒包含多少帧，默认为 `16`。
- **总帧数 (`frame_num`)**: 定义了生成的总帧数。

默认总帧数为 `81`，因此默认时长为 `81 帧 / 16 帧/秒 ≈ 5.06 秒`。

### 5.2 如何通过环境变量修改视频时长

为了方便在容器化环境中动态调整，视频总帧数 (`frame_num`) 可以通过环境变量 `WAN_FRAME_NUM` 进行配置，无需修改任何代码。

**配置方法：**

在启动模型（例如，运行 Docker 镜像）时，设置 `WAN_FRAME_NUM` 环境变量即可。系统会优先读取该环境变量的值，如果未设置，则使用默认值 `81`。

**示例：生成 10 秒时长的视频**

1.  **计算所需帧数**：为了保持模型内部的 `+1` 计算模式（例如 `5 * 16 + 1 = 81`），推荐使用公式 `时长 × 帧率 + 1` 来计算总帧数。
    - `10 秒 * 16 帧/秒 + 1 = 161`

2.  **设置环境变量**：在启动命令中加入环境变量。

    ```bash
    # 使用 docker run 启动时的示例
    docker run -e WAN_FRAME_NUM=161 your-image-name
    ```

    通过这种方式，模型将会生成一个包含 161 帧（约 10 秒）的视频。

### 5.3 重要警告与风险

**请务必了解，随意增加视频时长可能带来负面影响。**

模型的网络结构（尤其是用于感知时序关系的位置编码）和它所使用的训练数据，都是针对 5 秒左右的视频长度进行深度优化的。强制模型生成远超其训练范围的视频（一种“分布外”生成）可能会导致以下问题：

- **视频质量显著下降**：画面可能变得模糊、扭曲。
- **内容不连贯**：视频后半段可能与前半段逻辑脱节，或者开始重复单调的动作。
- **画面静止**：生成到一定长度后，画面可能“卡住”或变成静态图片。
- **程序报错**：超出长度的计算可能引发未预料到的维度错误。

因此，虽然技术上可以修改该参数，但**无法保证生成长视频的质量**。要获得高质量的长视频，通常需要使用专门为长视频设计的新数据集对模型进行微调（Fine-tuning）。
