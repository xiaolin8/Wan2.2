apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: wan22-ray-cluster
  namespace: hu
  annotations:
    ray.io/worker-group-idle-timeout-seconds: "600"
spec:
  enableInTreeAutoscaling: true
  headGroupSpec:
    rayStartParams:
      dashboard-host: 0.0.0.0
      num-cpus: "0"
    serviceType: NodePort
    template:
      spec:
        containers:
        - image: 172.31.0.182/system_containers/wan22-diffusers:1104
          imagePullPolicy: Always
          name: ray-head
          env:
          - name: NCCL_SOCKET_IFNAME
            value: ^lo,docker0,veth
          ports:
          - containerPort: 6379
            name: gcs-server
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          resources:
            limits:
              cpu: "16"
              memory: 256Gi
            requests:
              cpu: "4"
              memory: 8Gi
          securityContext:
            capabilities:
              add:
              - IPC_LOCK
          volumeMounts:
          - mountPath: /models
            name: model-storage
          - mountPath: /workspace/outputs
            name: output-storage
          - mountPath: /dev/shm
            name: dshm
          - name: accelerate-config-volume
            mountPath: /workspace/accelerate_config.yaml
            subPath: accelerate_config.yaml
        volumes:
        - hostPath:
            path: /data/Wan-AI
          name: model-storage
        - hostPath:
            path: /data/Wan-AI/output
          name: output-storage
        - emptyDir:
            medium: Memory
            sizeLimit: 128Gi
          name: dshm
        - name: accelerate-config-volume
          configMap:
            name: accelerate-config
  rayVersion: 2.10.0
  workerGroupSpecs:
  - groupName: gpu-worker-group
    maxReplicas: 2
    minReplicas: 2
    rayStartParams: {}
    replicas: 2
    template:
      spec:
        containers:
        - env:
          - name: PYTORCH_CUDA_ALLOC_CONF
            value: expandable_segments:True
          - name: NCCL_DEBUG
            value: INFO
          - name: NCCL_IB_DISABLE
            value: "0"
          - name: NCCL_SOCKET_IFNAME
            value: ^lo,docker0,veth
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: S3_ACCESS_KEY
                name: s3-credentials
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: S3_SECRET_KEY
                name: s3-credentials
          image: 172.31.0.182/system_containers/wan22-diffusers:1104
          imagePullPolicy: Always
          name: ray-worker
          resources:
            limits:
              cpu: "32"
              memory: 256Gi
              nvidia.com/gpu: "2"
              nvidia.com/priority: "0"
              t7d.com/rdma: "1"
            requests:
              cpu: "8"
              memory: 2Gi
              nvidia.com/gpu: "2"
              nvidia.com/priority: "0"
              t7d.com/rdma: "1"
          securityContext:
            capabilities:
              add:
              - IPC_LOCK
          volumeMounts:
          - mountPath: /models
            name: model-storage
          - mountPath: /workspace/outputs
            name: output-storage
          - mountPath: /dev/shm
            name: dshm
          - name: accelerate-config-volume
            mountPath: /workspace/accelerate_config.yaml
            subPath: accelerate_config.yaml
        tolerations:
        - effect: NoSchedule
          key: nvidia.com/gpu
          operator: Exists
        volumes:
        - hostPath:
            path: /data/Wan-AI
          name: model-storage
        - hostPath:
            path: /data/Wan-AI/output
          name: output-storage
        - emptyDir:
            medium: Memory
            sizeLimit: 128Gi
          name: dshm
        - name: accelerate-config-volume
          configMap:
            name: accelerate-config