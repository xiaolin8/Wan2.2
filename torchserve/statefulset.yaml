apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: wan22-distributed
spec:
  serviceName: wan22-distributed-svc
  replicas: 2
  selector:
    matchLabels:
      app: wan22-distributed
  template:
    metadata:
      labels:
        app: wan22-distributed
    spec:
      nodeSelector:
        gpu: "on" # 确保调度到有 GPU 的节点
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: wan22-distributed-model
              topologyKey: kubernetes.io/hostname
      containers:
        - name: torchserve-distributed
          image: 172.31.0.182/system_containers/wan22:torchserve
          ports:
            - containerPort: 8000
              name: http
            - containerPort: 8081
              name: management
          resources:
            limits:
              cpu: "64"
              memory: 128Gi
              nvidia.com/gpu: "4"
              t7d.com/rdma: "1"
            requests:
              cpu: "8"
              memory: 128Gi
              nvidia.com/gpu: "4"
              t7d.com/rdma: "1"
          env:
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NCCL_DEBUG_SUBSYS
              value: "ALL"
            - name: NCCL_IB_HCA
              value: "mlx5_0"
            - name: NCCL_SOCKET_IFNAME
              value: "ib0"
            - name: NCCL_IB_DISABLE
              value: "0"
            - name: MODEL_STORE
              value: "/home/model-server/model-store"
            - name: TS_CONFIG_FILE
              value: "/home/model-server/config.properties"
          volumeMounts:
            - mountPath: /data/Wan2.2-T2V-A14B
              name: data-volume
            - mountPath: /output
              name: output-volume
            - name: dshm
              mountPath: /dev/shm
            - name: model-store-rwx
              mountPath: /home/model-server/model-store
      volumes:
        - hostPath:
            path: /data/Wan-AI/Wan2.2-T2V-A14B
          name: data-volume
        - hostPath:
            path: /data/Wan-AI/output
          name: output-volume
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 128Gi