apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: wan22-generation-rayjob8
spec:
  backoffLimit: 0
  shutdownAfterJobFinishes: true
  entrypoint: python generate_ray.py --task "t2v-A14B" --size "832*480" --ckpt_dir
    /models/Wan2.2-T2V-A14B --ulysses_size 8 --prompt "A cinematic video. An astronaut in a white spacesuit walks cautiously on the red, dusty surface of Moon. The camera follows the astronaut from behind in a tracking shot. The astronaut stops and looks up in surprise at a giant, dark rock. The camera tilts up to reveal the word "tenxcloud" clearly engraved on the rock's surface. The scene is realistic, with a desolate Martian landscape and a faint sun in the background, creating a sense of mystery and discovery."
    --save_file /workspace/outputs/$(date '+%Y%m%d%H%M%S')-tenxcloud-from-ray.mp4
    --num-workers 8 --sample_guide_scale 10 --convert_model_dtype --offload_model True --t5_cpu --dit_fsdp
  rayClusterSpec:
    headGroupSpec:
      rayStartParams:
        dashboard-host: 0.0.0.0
      template:
        metadata: {}
        spec:
          containers:
          - image: 172.31.0.182/system_containers/wan22:1016-ray
            imagePullPolicy: Always
            env:
              - name: PYTORCH_CUDA_ALLOC_CONF
                value: expandable_segments:True            
            name: ray-head
            ports:
            - containerPort: 6379
              name: gcs-server
              protocol: TCP
            - containerPort: 8265
              name: dashboard
              protocol: TCP
            - containerPort: 10001
              name: client
              protocol: TCP
            resources:
              limits:
                memory: 256Gi
              requests:
                memory: 16Gi
            volumeMounts:
            - mountPath: /models
              name: model-storage
            - mountPath: /workspace/outputs
              name: output-storage
          volumes:
          - hostPath:
              path: /data/Wan-AI
            name: model-storage
          - hostPath:
              path: /data/Wan-AI/output
            name: output-storage
    rayVersion: 2.10.0
    workerGroupSpecs:
    - groupName: worker-group2
      maxReplicas: 1
      minReplicas: 1
      rayStartParams: {}
      replicas: 1
      scaleStrategy: {}
      template:
        metadata: {}
        spec:
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                      - key: ray.io/group
                        operator: In
                        values:
                          - worker-group2
                  topologyKey: kubernetes.io/hostname
          containers:
          - image: 172.31.0.182/system_containers/wan22:1016-ray
            imagePullPolicy: Always
            name: ray-worker
            env:
              - name: PYTORCH_CUDA_ALLOC_CONF
                value: expandable_segments:True            
            resources:
              limits:
                memory: 128Gi
                nvidia.com/gpu: "1"
                nvidia.com/gpumem: 64k
                t7d.com/rdma: "1"
              requests:
                memory: 32Gi
                nvidia.com/gpu: "1"
                nvidia.com/gpumem: 64k
                t7d.com/rdma: "1"
            securityContext:
              capabilities:
                add:
                - IPC_LOCK
            volumeMounts:
            - mountPath: /models
              name: model-storage
            - mountPath: /workspace/outputs
              name: output-storage
          tolerations:
          - effect: NoSchedule
            key: nvidia.com/gpu
            operator: Exists
          volumes:
          - hostPath:
              path: /data/Wan-AI
            name: model-storage
          - hostPath:
              path: /data/Wan-AI/output
            name: output-storage
  submissionMode: K8sJobMode
  ttlSecondsAfterFinished: 0