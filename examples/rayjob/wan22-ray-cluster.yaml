apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: wan22-ray-cluster
  annotations:
    ray.io/worker-group-idle-timeout-seconds: "600"
spec:
  rayVersion: '2.10.0'
  enableInTreeAutoscaling: true
  headGroupSpec:
    serviceType: NodePort
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: "0"
    template:
      spec:
        volumes:
          - name: model-storage
            hostPath:
              path: /data/Wan-AI
          - name: output-storage
            hostPath:
              path: /data/Wan-AI/output
          - name: dshm
            emptyDir:
              medium: Memory
              sizeLimit: 128Gi
        containers:
          - name: ray-head
            image: 172.31.0.182/system_containers/wan22:1016-ray
            imagePullPolicy: Always
            ports:
              - name: gcs-server
                containerPort: 6379
              - name: dashboard
                containerPort: 8265
              - name: client
                containerPort: 10001
            resources:
              limits:
                cpu: "16"
                memory: "256Gi"
              requests:
                cpu: "4"
                memory: "8Gi"
            securityContext:
              capabilities:
                add:
                  - IPC_LOCK
            volumeMounts:
              - name: model-storage
                mountPath: /models
              - name: output-storage
                mountPath: /workspace/outputs
              - name: dshm
                mountPath: /dev/shm
  workerGroupSpecs:
    - replicas: 1
      minReplicas: 1
      maxReplicas: 2
      groupName: gpu-worker-group
      rayStartParams: { }
      template:
        spec:
          # schedulingGates:
          #   - name: "tenxcloud.com/scheduling-gate"
          # timeoutSeconds: 600
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          containers:
            - name: ray-worker
              image: 172.31.0.182/system_containers/wan22:1016-ray
              imagePullPolicy: Always
              env:
                - name: PYTORCH_CUDA_ALLOC_CONF
                  value: expandable_segments:True
#                - name: CUDA_DISABLE_CONTROL
#                  value: "true"
#                - name: NVIDIA_VISIBLE_DEVICES
#                  value: "all"
                - name: NCCL_DEBUG
                  value: "INFO"
                - name: NCCL_IB_DISABLE
                  value: "0"
                - name: NCCL_SOCKET_IFNAME
                  value: "^lo,docker0,veth"
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: s3-credentials
                      key: S3_ACCESS_KEY
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: s3-credentials
                      key: S3_SECRET_KEY
              resources:
                limits:
                  cpu: "32"
                  memory: "256Gi"
                  t7d.com/rdma: "1"
                  nvidia.com/gpu: "4"
                  nvidia.com/priority: "0"
                requests:
                  cpu: "8"
                  memory: "2Gi"
                  t7d.com/rdma: "1"
                  nvidia.com/gpu: "4"
                  nvidia.com/priority: "0"
              securityContext:
                capabilities:
                  add:
                    - IPC_LOCK
              volumeMounts:
                - name: model-storage
                  mountPath: /models
                - name: output-storage
                  mountPath: /workspace/outputs
                - name: dshm
                  mountPath: /dev/shm
          volumes:
            - name: model-storage
              hostPath:
                path: /data/Wan-AI
            - name: output-storage
              hostPath:
                path: /data/Wan-AI/output
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 128Gi