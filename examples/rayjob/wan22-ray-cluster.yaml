apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: wan22-ray-cluster-2
  annotations:
    ray.io/worker-group-idle-timeout-seconds: "600"
spec:
  rayVersion: '2.10.0'
  enableInTreeAutoscaling: true
  headGroupSpec:
    serviceType: NodePort
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: "0"
    template:
      spec:
        containers:
          - name: ray-head
            image: 172.31.0.182/system_containers/wan22:1016-ray
            imagePullPolicy: IfNotPresent
            env:
              - name: PYTORCH_CUDA_ALLOC_CONF
                value: expandable_segments:True
              - name: CUDA_DISABLE_CONTROL
                value: "true"
            ports:
              - name: gcs-server
                containerPort: 6379
              - name: dashboard
                containerPort: 8265
              - name: client
                containerPort: 10001
            resources:
              limits:
                cpu: "16"
                memory: "256Gi"
              requests:
                cpu: "1"
                memory: "2Gi"
  workerGroupSpecs:
    - replicas: 0
      minReplicas: 0
      maxReplicas: 20
      groupName: gpu-worker-group
      rayStartParams: { }
      template:
        spec:
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          containers:
            - name: ray-worker
              image: 172.31.0.182/system_containers/wan22:1016-ray
              imagePullPolicy: IfNotPresent
              env:
                - name: PYTORCH_CUDA_ALLOC_CONF
                  value: expandable_segments:True
                - name: CUDA_DISABLE_CONTROL
                  value: "true"
              resources:
                limits:
                  cpu: "16"
                  memory: "256Gi"
                  nvidia.com/gpu: "1"
                  nvidia.com/priority: "0"
                requests:
                  cpu: "1"
                  memory: "2Gi"
                  nvidia.com/gpu: "1"
                  nvidia.com/priority: "0"
              securityContext:
                capabilities:
                  add:
                    - IPC_LOCK
              volumeMounts:
                - name: model-storage
                  mountPath: /models
                - name: output-storage
                  mountPath: /workspace/outputs
          volumes:
            - name: model-storage
              hostPath:
                path: /data/Wan-AI
            - name: output-storage
              hostPath:
                path: /data/Wan-AI/output
