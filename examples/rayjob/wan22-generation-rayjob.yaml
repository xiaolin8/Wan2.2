apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: wan22-rayjob
spec:
  entrypoint: python generate_ray.py --task t2v-A14B --size "832*480" --ckpt_dir /models/Wan2.2-T2V-A14B
    --ulysses_size 4 --prompt "A cinematic video of an astronaut walking on Mars and discovering a giant stone engraved with 'TenxCloud'."
    --save_file /workspace/outputs/$(date '+%Y%m%d%H%M%S')-tenxcloud-from-ray.mp4 --num-workers 4
    --sample_guide_scale 10 --convert_model_dtype --offload_model True --t5_cpu --dit_fsdp
  shutdownAfterJobFinishes: false
  rayClusterSpec:
    rayVersion: '2.10.0'
    headGroupSpec:
      rayStartParams:
        dashboard-host: '0.0.0.0'
        num-cpus: "0"
      template:
        spec:
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                      - key: ray.io/group
                        operator: In
                        values:
                          - gpu-worker-group
                  topologyKey: kubernetes.io/hostname
          containers:
            - name: ray-head
              image: 172.31.0.182/system_containers/wan22:1016-ray
              imagePullPolicy: Always
              env:
                - name: PYTORCH_CUDA_ALLOC_CONF
                  value: expandable_segments:True
              ports:
                - name: gcs-server
                  containerPort: 6379
                - name: dashboard
                  containerPort: 8265
                - name: client
                  containerPort: 10001
              resources:
                limits:
                  memory: "256Gi"
                  nvidia.com/gpu: "1"
                  cpu: "8"
                requests:
                  memory: "16Gi"
                  nvidia.com/gpu: "1"
                  cpu: "8"
              volumeMounts:
                - name: model-storage
                  mountPath: /models
                - name: output-storage
                  mountPath: /workspace/outputs
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          volumes:
            - name: model-storage
              hostPath:
                path: /data/Wan-AI
            - name: output-storage
              hostPath:
                path: /data/Wan-AI/output
    workerGroupSpecs:
      - replicas: 1
        minReplicas: 1
        maxReplicas: 1
        groupName: gpu-worker-group
        rayStartParams: {}
        template:
          spec:
            affinity:
              podAntiAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                  - labelSelector:
                      matchExpressions:
                        - key: ray.io/group
                          operator: In
                          values:
                            - gpu-worker-group
                    topologyKey: kubernetes.io/hostname
            tolerations:
              - key: "nvidia.com/gpu"
                operator: "Exists"
                effect: "NoSchedule"
            containers:
              - name: ray-worker
                image: 172.31.0.182/system_containers/wan22:1016-ray
                imagePullPolicy: Always
                env:
                  - name: PYTORCH_CUDA_ALLOC_CONF
                    value: expandable_segments:True
                resources:
                  limits:
                    memory: 128Gi
                    nvidia.com/gpu: "2"
                  requests:
                    memory: 128Gi
                    nvidia.com/gpu: "2"
                securityContext:
                  capabilities:
                    add:
                    - IPC_LOCK
                volumeMounts:
                  - name: model-storage
                    mountPath: /models
                  - name: output-storage
                    mountPath: /workspace/outputs
            volumes:
              - name: model-storage
                hostPath:
                  path: /data/Wan-AI
              - name: output-storage
                hostPath:
                  path: /data/Wan-AI/output
