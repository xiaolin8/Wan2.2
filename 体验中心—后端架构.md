## 1. 架构分层

### 1.1. 接入层

#### 1.1.1 网关路由

这一层的职责是直接接收用户/客户端请求，并对请求进行权限的认证和校验，以及请求的限流（RPM、TPM）控制。

网关的职责不再是直接连接到模型，而是作为“MaaS 管控端”的 API 代理。所有与任务相关的请求都将通过网关路由到管控端。

我们需要定义至少三个核心路由：

1.  **任务提交 API**：用于创建新的视频生成任务。
2.  **任务状态 API**：用于查询已提交任务的状态和结果。
3.  **任务取消/删除 API**：用于取消或删除已提交任务。

**airbrix 默认路由：**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: aibrix-reserved-router
  namespace: aibrix-system
spec:
  parentRefs:
    - name: aibrix-eg
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
        - path:
            type: PathPrefix
            value: /v1/completions
        - path:
            type: PathPrefix
            value: /v1/embeddings
        - path:
            type: PathPrefix
            value: /v1/image/generations
        # 视频生成
        - path:
            type: PathPrefix
            value: /v1/video/generations
      backendRefs:
        - name: aibrix-gateway-plugins
          port: 50052
```



#### 1.1.2 接口设计

##### 1. 视频生成-基于文本或首帧

POST https://<GATEWAY-IP>/v1/video/generations

```bash
curl --location 'https://<GATEWAY-IP>/v1/video/generations' \
    -H "Authorization: Bearer $API_KEY" \
    -H 'Content-Type: application/json' \
    -d '{
    "model": "wan2.2-i2v",
    "type": "image_to_video",
    "input": {
        "prompt": "一只猫在草地上奔跑",
        "image": "data:image/png;base64,aHR0******cG5n"
    },
    "parameters": {
        "resolution": "720P",
        "prompt_extend": false
    }
}'
```

- **prompt** `*string*` **（必选）**：支持中英文，每个汉字/字母占一个字符，超过部分会自动截断。长度不超过800个字符。

- **negative_prompt** `*string*` （可选）：
  反向提示词，用来描述不希望在视频画面中看到的内容，可以对视频画面进行限制。

  支持中英文，长度不超过500个字符，超过部分会自动截断。

  示例值：低分辨率、错误、最差质量、低质量、残缺、多余的手指、比例不良等。

- **image** `*string*` **（必选）**

  - 首帧图像的 URL 或 Base64 编码数据。

  - 图像限制：

    - 图像格式：JPEG、JPG、PNG（不支持透明信道）、BMP、WEBP。
    - 图像分辨率：图像的宽度和高度范围为[360, 2000]，单位为像素。
    - 文档大小：不超过10MB。

  - 输入图像说明：

    1. 使用公网可访问URL
       - 支持 HTTP 或 HTTPS 协议。
       - 示例值：`https://cdn.translate.alibaba.com/r/wanx-demo-1.png`。
    2. 传入 Base64 编码图像后的字符串
       - 数据格式：`data:{MIME_type};base64,{base64_data}`。
       - 示例值：`data:image/png;base64,GDU7MtCZzEbTbmRZ......`。（编码字符串过长，仅展示片段）

  - **resolution** `*string*` （可选）

    - 用于指定生成的视频分辨率档位。仅用于调整视频的清晰度（总像素），不改变视频的宽高比，**视频宽高比将与输入图像 img_url 的宽高比保持一致**。

      此参数的默认值和可用枚举值依赖于 model 参数，规则如下：

      - wan2.2：可选值：480P、720P、1080P。默认值为`480P`。

  - **duration** `*integer*` （可选）

    - 生成视频的时长，单位为秒。该参数的取值依赖于 model参数：
      - wan2.2：固定为5秒，且不支持修改。

  - **prompt_extend** `*boolean*` （可选）

    是否开启prompt智能改写。开启后使用大模型对输入prompt进行智能改写。对于较短的prompt生成效果提升明显，但会增加耗时。

    - true：默认值，开启智能改写。
    - false：不开启智能改写。

  - **watermark** `*boolean*` （可选）

    是否添加水印标识，水印位于视频右下角，文案固定为“AI生成”。

    - false：默认值，不添加水印。
    - true：添加水印。

  - **seed** `*integer*` （可选）

    随机数种子，取值范围为`[0, 2147483647]`。

    未指定时，系统自动生成随机种子。若需提升生成结果的可复现性，建议固定seed值。

    请注意，由于模型生成具有概率性，即使使用相同 seed，也不能保证每次生成结果完全一致。

    

**正常响应参数**

```bash
{
    "output": {
        "task_status": "QUEUED",
        "task_id": "0385dc79-5ff8-4d82-bcb6-xxxxxx" // 任务ID。查询有效期24小时。
    },
    "request_id": "4909100c-7b5a-9f92-bfe5-xxxxxx"
}
```

- **task_status** `*string*`（任务状态）
  - QUEUED：任务排队中
  - RUNNING：任务处理中
  - SUCCEEDED：任务执行成功
  - FAILED：任务执行失败
  - CANCELED：任务已取消
  - UNKNOWN：任务不存在或状态未知

**异常响应参数**

```bash
{
    "code":"InvalidApiKey",
    "message":"Invalid API-key provided.",
    "request_id":"fb53c4ec-1c12-4fc4-a580-xxxxxx"
}
```



##### 2. 取消或删除任务

```bash
curl -X DELETE https://<GATEWAY-IP>/api/v1/video/generations/$TASK_ID \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $API_KEY"
```

任务状态不同，调用 DELETE 接口，执行的操作有所不同，具体说明如下：

| 当前任务状态 | 支持DELETE操作           | 操作含义                                  | DELETE操作后任务状态 |
| ------------ | ------------------------ | ----------------------------------------- | -------------------- |
| QUEUED       | 是                       | 任务取消排队，任务状态被变更为 CANCELED。 | CANCELED             |
| RUNNING      | 不支持                   | -                                         | -                    |
| SUCCEEDED    | 是                       | 删除视频生成任务记录，后续将不支持查询。  | -                    |
| FAILED       | 是                       | 删除视频生成任务记录，后续将不支持查询。  | -                    |
| CANCELED     | 不支持，24小时后自动删除 | -                                         | -                    |



##### 3. 根据任务ID查询结果

GET https://<GATEWAY-IP>/v1/video/generations/{TASK_ID}

- **轮询建议**：视频生成过程约需数分钟，建议采用**轮询**机制，并设置合理的查询间隔（如 15 秒）来获取结果。
- **任务状态流转**：QUEUED（排队中）→ RUNNING（处理中）→ SUCCEEDED（成功）/ FAILED（失败）。
- **结果链接**：任务成功后返回视频链接，有效期为 **24 小时**。建议在获取链接后立即下载并转存至永久存储（如对象存储）。
- **task_id 有效期**：**24小时**，超时后将无法查询结果，接口将返回任务状态为`UNKNOWN`。

```bash
curl -X GET https://<GATEWAY-IP>/api/v1/video/generations/tasks/86ecf553-d340-4e21-xxxxxxxxx \
--header "Authorization: Bearer $API_KEY"
```

任务执行成功响应：

> 视频 URL 仅保留 24 小时，超时后会被自动清除，请及时保存生成的视频。

```bash
{
    "success": true,
    "code": 200,
    "data": {
        "id": 514465659,
        "gmtCreate": "2025-10-25 10:51:37",
        "gmtCreateTimeStamp": 1761360697000,
        "submit_time": "2025-10-25 11:07:28.590",
        "scheduled_time": "2025-10-25 11:07:35.349",
        "completed_time": null,
        "model": "Wan2.2-T2V-14B",
        "taskId": "c7ac5c50cc6643d6a4ee50134548522a",
        "taskStatus": "RUNNING",
        "taskInput": {
            "prompt": "一个金发碧眼的女性站在复古建筑前，背景是，广角镜头，拉出的宏大场景，晴天光，微风吹起裙摆，画面充满复古与优雅气息，镜头拉远，复古胶片风格。",
            "actual_prompt": null, // 开启 prompt 智能改写后，返回实际使用的优化后 prompt。若未开启该功能，则不返回此字段。
            "resolution": "720", // 生成视频的分辨率。枚举值为480、720、1080。
            "duration": 5,  // 计费公式：费用 = 视频秒数 × 单价。
            "video_count": 1, // 生成视频的数量。固定为1。
            "video_url": null,
            "seed": 10, // 随机数种子，用于控制生成内容的随机性。取值范围 `[0, 2147483647]`。不提供则自动生成。相同 seed 可能复现相似结果。
        },
        "taskType": "text_to_video",
        "taskProgress": 97, // 任务进度
        "mediaType": "video"
    },
    "requestId": "9d126a34e4cee3b08c02874cd9a5268f",
    "failed": false
}
```



任务执行失败：

```bash
{
    "request_id": "e5d70b02-ebd3-98ce-9fe8-759d7d7b107d",
    "data": {
        "task_id": "86ecf553-d340-4e21-af6e-a0c6a421c010",
        "task_status": "FAILED",
        "code": "InvalidParameter",
        "message": "The size is not match xxxxxx"
    }
}
```



任务查询过期：

> task_id查询有效期为 24 小时，超时后将无法查询，返回以下报错信息。

```bash
{
    "request_id": "a4de7c32-7057-9f82-8581-xxxxxx",
    "data": {
        "task_id": "502a00b1-19d9-4839-a82f-xxxxxx",
        "task_status": "UNKNOWN"
    }
}
```





### 1.2. 控制层——MaaS 管控端

在转为常驻服务模式后，管控端的职责发生了根本性转变。它不再是创建和管理批处理作业的“工厂”，而是作为一个**智能的API网关和请求路由器**，直接与后端的 RayServe 推理服务集群进行通信。

#### 1.2.1. 核心职责

1.  **认证与授权**：接收来自接入层网关的请求，校验用户身份和API Key的有效性。
2.  **任务持久化与状态管理**：生成全局唯一的 `task_id`，并将任务的初始信息（如prompt、用户ID、状态=`QUEUED`）存入数据库。
3.  **服务路由与QoS分发**：根据用户等级或请求参数，判断该请求应被发送到哪个后端的 RayServe 集群（如“高优先级集群”或“普通集群”），实现服务质量（QoS）的差异化。
4.  **异步任务提交**：通过 HTTP/gRPC 协议，将生成请求**直接提交**给目标 RayServe 服务的入口点（Ingress）。RayServe 服务自身被设计为异步处理，会立即返回确认信息，而生成过程则在后端集群中异步执行。

**请求转发示例 (Python)**:
```python
# 管控端内部逻辑示例
async def submit_task_to_rayserve(user_request: dict, user_tier: str):
    task_id = generate_unique_task_id()
    
    # 根据用户等级选择目标服务
    if user_tier == "premium":
        rayserve_endpoint = "http://rayservice-premium.ray-namespace.svc/generate"
    else:
        rayserve_endpoint = "http://rayservice-default.ray-namespace.svc/generate"
        
    # 构造提交给 RayServe 的请求体
    rayserve_payload = {
        "task_id": task_id,
        "prompt": user_request.get("prompt"),
        "image_url": user_request.get("input", {}).get("img_url"),
        # ... 其他参数
    }
    
    # 将任务信息预存入数据库
    await db.save_task(task_id, status="QUEUED", payload=rayserve_payload)
    
    # 异步调用 RayServe 服务
    async with httpx.AsyncClient() as client:
        response = await client.post(rayserve_endpoint, json=rayserve_payload, timeout=10)
        response.raise_for_status() # 确保请求被成功接收
        
    # RayServe 已接收任务，向用户返回 task_id
    return {"task_id": task_id, "task_status": "QUEUED"}
```

### 1.3. 服务路由与 QoS 保障

为了有效管理昂贵的 GPU 资源，并为不同级别的用户提供差异化的服务质量（QoS），我们摒弃了基于作业的 Kueue 排队系统，转而采用**多租户、多实例的 RayServe 集群部署模式**。

这种模式通过部署多个相互隔离的 `RayService` 实例来实现资源隔离和优先级划分，比在单个服务内部实现复杂的优先级队列逻辑要更简单、更稳定。

**核心组件与概念**:

-   **RayCluster**: 一个独立的 Ray 计算集群，由一个 Head Pod 和多个 Worker Pod 组成，拥有自己专属的计算资源（CPU, Memory, GPU）。
-   **RayService**: KubeRay 提供的 CRD，用于定义和管理一个完整的 RayServe 应用，包括底层的 `RayCluster` 和部署在上面的 `Serve` 应用。

**通过多 `RayService` 实例实现差异化 QoS**:

1.  **资源配额隔离**：我们可以为高、低两种优先级的用户分别创建两个独立的 `RayService`。例如，在总共 10 个 GPU 的集群中，我们可以为 `rayservice-premium` 分配 8 个 GPU，而为 `rayservice-default` 只分配 2 个。

    ```yaml
    # 高级用户服务，拥有 8 个 GPU
    apiVersion: ray.io/v1
    kind: RayService
    metadata:
      name: rayservice-premium
    spec:
      serveConfigV2: # Ray Serve 应用配置
        # ...
      rayClusterConfig:
        rayVersion: '2.9.0'
        headGroupSpec: # Head Pod 配置
          # ...
        workerGroupSpecs: # Worker Pod 配置
        - groupName: gpu-workers-premium
          replicas: 4 # 4个Worker Pod
          minReplicas: 2
          maxReplicas: 4
          rayStartParams: {}
          template:
            spec:
              containers:
              - name: ray-worker
                image: 172.31.0.182/system_containers/wan22:1024
                resources:
                  limits:
                    nvidia.com/gpu: "2" # 每个Worker Pod 2个GPU
    ---
    # 普通用户服务，拥有 2 个 GPU
    apiVersion: ray.io/v1
    kind: RayService
    metadata:
      name: rayservice-default
    spec:
      # ...（类似配置，但资源较少）
      rayClusterConfig:
        workerGroupSpecs:
        - groupName: gpu-workers-default
          replicas: 1
          # ...
          template:
            spec:
              containers:
              - name: ray-worker
                resources:
                  limits:
                    nvidia.com/gpu: "2" # 1个Worker Pod，2个GPU
    ```

2.  **请求路由**：MaaS 管控端（见 1.2 节）负责将来自不同用户的请求路由到正确的 `RayService` K8s Service 入口。高级用户的请求会被发往 `rayservice-premium`，享受更多的资源和更快的响应；普通用户的请求则发往 `rayservice-default`。

任务提交流程图：
```mermaid
sequenceDiagram
    participant User as 用户
    participant Controller as 管控端 (API)
    participant Database as 任务数据库
    participant PremiumRay as 高优先级 RayService
    participant DefaultRay as 普通 RayService

    User->>Controller: 提交生成请求
    Controller->>Controller: 识别用户为"高级用户"
    Controller->>Database: 保存任务信息 (status='QUEUED')
    Controller->>PremiumRay: HTTP POST /generate (含task_id)
    Note over PremiumRay: RayServe内部接收请求, <br/>立即返回确认, <br/>并在后台GPU上异步执行生成
    PremiumRay-->>Controller: 确认接收 (HTTP 200 OK)
    Controller-->>User: 返回任务ID，告知排队中
```

**工作流程**:

1.  **接收请求**: 管控端的 API 服务接收到用户请求。
2.  **身份识别与持久化**: 服务识别用户身份（租户/优先级），生成 `task_id`，并将任务信息存入数据库。
3.  **路由与提交**: 管控端根据用户身份，选择对应的 `RayService` Endpoint (e.g., `rayservice-premium` or `rayservice-default`)，并通过 HTTP **直接将请求提交给 RayServe 服务**。
4.  **RayServe 异步执行**: RayServe 应用接收到请求后，立即将任务放入其内部的执行队列，并向管控端返回成功接收的响应。Ray Serve 的 Deployment Actor 会从队列中获取任务，在分配到的 GPU 资源上执行视频生成。
5.  **返回响应**: API 服务在收到 RayServe 的确认后，立即向用户返回 `task_id`，告知任务已开始处理。

### 1.4. 推理服务执行层

这一层由 `RayService` 和其管理的 `RayCluster` 构成，是实际执行计算密集型推理任务的核心。

-   **常驻服务**: 与 `PyTorchJob` 的“用完即焚”模式不同，`RayCluster` 是一个**常驻的、有状态的**计算集群。这意味着模型加载、代码初始化等耗时操作在服务启动时就已完成，后续的推理请求可以被立即处理，大大降低了冷启动延迟。
-   **资源管理与自动伸缩**: `RayService` 支持基于流量的自动伸缩（Autoscaling）。我们可以为其 Worker Group 设置 `minReplicas` 和 `maxReplicas`，Ray 会根据入口请求的负载（QPS）自动增减 Worker Pod 的数量，实现资源的弹性伸缩。
-   **任务执行**: Ray Serve 的 `Deployment` 是一组可扩展的 Python 类实例（Actor）。每个实例（副本）可以加载一个模型，并独立处理请求。在我们的场景中，每个 Actor 接收到生成任务后，会执行与原 `PyTorchJob` 脚本类似的逻辑：下载数据、执行推理、上报进度、上传结果。


## 2. 一次完整的视频生成过程





下面是集成了 RayServe 的、新的端到端工作流：





```mermaid


sequenceDiagram


    participant User as 用户


    participant Frontend as 前端UI


    participant Controller as MaaS管控端


    participant RayService as RayServe 推理服务


    participant RedisStream as 进度/结果流


    participant RayActor as Ray Serve Actor (运行在GPU上)





    %% -- 任务提交与入队 --


    User->>Frontend: 1. 提交请求


    Frontend->>Controller: 2. 发送API请求


    Controller->>RayService: 3. (根据用户等级) HTTP请求到指定RayService


    Note over RayService: RayServe Ingress接收请求, <br/>并将其转发给一个空闲的Actor


    Controller-->>Frontend: 4. 告知排队中, 建立WebSocket连接





    %% -- 任务执行 --


    RayService->>RayActor: 5. 将请求分配给一个Actor副本


    


    activate RayActor


    Note over RayActor: 6. Actor内部逻辑开始执行


    RayActor->>RedisStream: 7. 实时上报进度 (XADD)


    Note over RayActor: 8. 后处理, 上传视频到S3


    RayActor->>RedisStream: 9. 上报最终结果与S3 URL (XADD)


    deactivate RayActor





    %% -- 结果通知 --


    activate Controller


    Controller->>RedisStream: (XREADGROUP) 持续消费流消息


    Controller->>Frontend: 10. (WebSocket) 实时推送进度/结果


    deactivate Controller





    Frontend-->>User: 11. 实时更新UI (进度条/最终视频)


```





采用 RayServe 后的用户请求流程：





1.  **用户提交**: 用户在前端界面输入 prompt，上传图片，点击“生成”。


2.  **请求处理与路由**: MaaS 管控端的 API 服务接收到请求。它识别用户身份，生成 `task_id`，将任务信息存入**任务数据库**。然后，它根据用户等级，选择正确的 `RayService` 入口，**直接发起 HTTP 请求**。


3.  **建立实时通道**: 前端与管控端建立 **WebSocket** 连接，用于接收实时通知。


4.  **RayServe 接收与调度**: `RayService` 的 HTTP Ingress 接收到请求，并将其转发给一个可用的模型服务副本（Actor）。如果所有副本都在忙，Ray Serve 会将请求放入队列中等待。


5.  **异步执行与进度上报**: Actor 副本在自己的进程和 GPU 上开始执行耗时的视频生成任务。在执行过程中，它通过 **Redis Stream** 实时汇报进度（例如，当前完成百分之多少）。


6.  **结果后处理与通知**: 任务完成后，Actor 将生成的视频上传到 S3，并通过 Redis Stream 发送包含 S3 链接的“完成”消息。


7.  **结果推送**: 管控端作为 Redis Stream 的消费者，监听到进度和完成消息，通过 WebSocket 将这些信息实时推送给前端。


8.  **前端 UI**: 前端根据收到的实时消息，更新界面上的进度条，并最终向用户展示生成的视频。



## 参考

- https://bailian.console.alibabacloud.com/?tab=api#/api/?type=model&url=2867393
- https://www.volcengine.com/docs/82379/1520757