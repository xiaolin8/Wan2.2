apiVersion: ray.io/v1
kind: RayService
metadata:
  name: wan22-rayservice
spec:
  # -------------------------------------------------------------------
  # Part 1: Ray Serve Application Definition
  # This section tells Ray Serve what application to run on the cluster.
  # -------------------------------------------------------------------
  serveConfigV2: |
    applications:
    - name: video_generation_service
      route_prefix: /generate
      import_path: serve_app:app
      runtime_env:
        pip:
          - redis
          - torch
          - torchvision
          - transformers
          - accelerate
          - diffusers
        env_vars:
          TOTAL_WORKERS: "2"
          REDIS_HOST: "172.31.0.181"
          REDIS_PORT: "6379"

  # -------------------------------------------------------------------
  # Part 2: Ray Cluster Definition
  # This is the spec for the underlying compute cluster.
  # -------------------------------------------------------------------
  rayClusterConfig:
    rayVersion: '2.9.3'
    headGroupSpec:
      rayStartParams:
        dashboard-host: '0.0.0.0'
      template:
        spec:
          containers:
            - name: ray-head
              image: 172.31.0.182/system_containers/wan22-ray:1026
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265
                  name: dashboard
              resources:
                requests:
                  cpu: "2"
                  memory: "4Gi"
                limits:
                  cpu: "4"
                  memory: "8Gi"
    workerGroupSpecs:
      - groupName: gpu-workers
        replicas: 2
        minReplicas: 2
        maxReplicas: 4
        rayStartParams: {}
        template:
          spec:
            containers:
              - name: ray-worker
                image: 172.31.0.182/system_containers/wan22-ray:1026
                resources:
                  requests:
                    cpu: "4"
                  limits:
                    cpu: "64"
                    memory: 256Gi
                    nvidia.com/gpu: "2"
                    t7d.com/rdma: "1"
                env:
                  - name: TOTAL_WORKERS
                    value: "2"
                  - name: REDIS_HOST
                    value: "172.31.0.181"
                  - name: NVIDIA_VISIBLE_DEVICES
                    value: "all"
                  - name: NCCL_IB_DISABLE
                    value: "0"
                  - name: NCCL_SOCKET_IFNAME
                    value: "^lo,docker0,veth"
                  - name: AWS_ACCESS_KEY_ID
                    valueFrom:
                      secretKeyRef:
                        name: s3-credentials
                        key: S3_ACCESS_KEY
                  - name: AWS_SECRET_ACCESS_KEY
                    valueFrom:
                      secretKeyRef:
                        name: s3-credentials
                        key: S3_SECRET_KEY
                volumeMounts:
                  - name: data-volume
                    mountPath: /data/Wan2.2-I2V-A14B
                  - name: dshm
                    mountPath: /dev/shm
            volumes:
              - name: data-volume
                hostPath:
                  path: /data/Wan-AI/Wan2.2-I2V-A14B
              - name: dshm
                emptyDir:
                  medium: Memory
                  sizeLimit: 128Gi
