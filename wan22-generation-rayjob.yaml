apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: wan22-generation-rayjob
spec:
  entrypoint: >-
    python generate_ray.py
      --task "t2v-A14B"
      --size "832*480"
      --ckpt_dir /models/Wan2.2-T2V-A14B
      --prompt "A cinematic video of an astronaut walking on Mars and discovering a giant stone engraved with 'TenxCloud'."
      --save_file /workspace/outputs/$(date '+%Y%m%d%H%M%S')-tenxcloud-from-ray.mp4
      --num-workers 4
      --offload_model True
      --t5_cpu
      --dit_fsdp
      --t5_fsdp

  # 任务完成后，自动删除 Ray 集群
  shutdownAfterJobFinishes: true
  rayClusterSpec:
    rayVersion: '2.10.0' # 最好指定 Ray 的版本
    headGroupSpec:
      rayStartParams:
        dashboard-host: '0.0.0.0'
      template:
        spec:
          containers:
            - name: ray-head
              image: 172.31.0.182/system_containers/wan22:1016-ray
              imagePullPolicy: Always
              ports:
                - name: gcs-server
                  containerPort: 6379
                - name: dashboard
                  containerPort: 8265
                - name: client
                  containerPort: 10001
              resources:
                limits:
                  cpu: "2"
                  memory: "8Gi"
                requests:
                  cpu: "2"
                  memory: "8Gi"
          volumes:
            - name: model-storage
              hostPath:
                path: /data/Wan-AI
            - name: output-storage
              hostPath:
                path: /data/Wan-AI/output

    workerGroupSpecs:
      - replicas: 1
        minReplicas: 1
        maxReplicas: 1
        groupName: gpu-worker-group
        rayStartParams: {}
        template:
          spec:
            tolerations:
              - key: "nvidia.com/gpu"
                operator: "Exists"
                effect: "NoSchedule"
            containers:
              - name: ray-worker
                image: 172.31.0.182/system_containers/wan22:1016-ray
                imagePullPolicy: Always
                resources:
                  limits:
                    memory: 128Gi
                    nvidia.com/gpu: "4"
                  requests:
                    memory: 128Gi
                    nvidia.com/gpu: "4"
            volumes:
              - name: model-storage
                hostPath:
                  path: /data/Wan-AI
              - name: output-storage
                hostPath:
                  path: /data/Wan-AI/output